{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj5vDCuEybpMnr8QW0HshB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiwa-debug/IPC_model/blob/main/successful.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data retrivation"
      ],
      "metadata": {
        "id": "Zr05xClsJuGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ5-s6ucluuB",
        "outputId": "3b6a22f4-f4f2-418f-9f60-8ce654d251dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xlsxwriter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "from openpyxl import load_workbook\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "SOWZ2ryYl2pZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e7fb91-c220-4961-e9cd-236ae5f234b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def IPC_Self_learning_Model(text):\n",
        "  train_data=pd.read_excel(\"ipc_data_1.xlsx\")\n",
        "  X = train_data[\"Offence\"].to_list()\n",
        "  X = np.array(X)\n",
        "  train_data_1= train_data['Section']\n",
        "  train_data_1 = train_data_1.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "  multilabel = MultiLabelBinarizer()\n",
        "  y = multilabel.fit_transform(train_data_1)\n",
        "\n",
        "\n",
        "  # Define feature extractor model using TF Hub layer\n",
        "  inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "  pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "  x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "  # Note: you could add more layers here if you wanted to\n",
        "  outputs = layers.Dense(len(multilabel.classes_), activation=\"softmax\")(x) # create the output layer\n",
        "  model_1 = tf.keras.Model(inputs=inputs,\n",
        "                          outputs=outputs)\n",
        "  \n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "  model_1.fit(X,  y,\n",
        "               epochs=30,\n",
        "                verbose=0)\n",
        "  \n",
        "  text = np.array([text])\n",
        "  model_1_pred_probs = model_1.predict(text)\n",
        "  n=2\n",
        "  indices_2 = (-model_1_pred_probs).argsort()[:n]\n",
        "  q=[]\n",
        "  for r in range(0,4):\n",
        "    q.append(multilabel.classes_[indices_2[0,r]])\n",
        "  \n",
        "\n",
        "  return q"
      ],
      "metadata": {
        "id": "DtdvQsoOl7IA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IPC_Check(pred,res):\n",
        "  g=[]\n",
        "  for r in res:\n",
        "    if r in pred:\n",
        "      g.append(True)\n",
        "    else:\n",
        "      g.append(False)\n",
        "  if False in g:\n",
        "    u=\"wrong\"\n",
        "  else:\n",
        "    u=\"right\"\n",
        "  return u"
      ],
      "metadata": {
        "id": "7ijy--BZv3jV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Improve(result,off,sec):\n",
        "  if result==\"wrong\":\n",
        "\n",
        "    sec=str(sec)\n",
        "\n",
        "\n",
        "    myFileName=r'ipc_data_1.xlsx'\n",
        "    #load the workbook, and put the sheet into a variable\n",
        "    wb = load_workbook(filename=myFileName)\n",
        "    ws = wb['Sheet1']\n",
        "\n",
        "    #max_row is a sheet function that gets the last row in a sheet.\n",
        "    newRowLocation = ws.max_row \n",
        "\n",
        "    #write to the cell you want, specifying row and column, and value :-)\n",
        "    ws.cell(column=2,row=newRowLocation, value=sec)\n",
        "    ws.cell(column=3,row=newRowLocation, value=off)\n",
        "    wb.save(filename=myFileName)\n",
        "    wb.close()"
      ],
      "metadata": {
        "id": "qwu5ZBJOpDMY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ],
      "metadata": {
        "id": "ZfDbgESLJ2BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "offence_ =\"riot and murder\"\n",
        "section_ = ['146 IPC', '302 IPC']"
      ],
      "metadata": {
        "id": "SvQ0dN_iKAcX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ipc = IPC_Self_learning_Model(offence_)\n"
      ],
      "metadata": {
        "id": "25dNHzCz8jEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf29d884-1db3-4c2c-f3dd-7d8daf7f217b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 347ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ipc"
      ],
      "metadata": {
        "id": "ekte8k19N9MF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef617274-cd30-47eb-ff2b-07c20bae4012"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['147 IPC', '148 IPC', '506 IPC', '153 IPC']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = IPC_Check(pred_ipc, section_)"
      ],
      "metadata": {
        "id": "1gC0L64FKknT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mBKg__7AKyaj",
        "outputId": "f4e4e9ca-a678-4b3c-f5a5-c766893ad704"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wrong'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Improve(result, offence_, section_)"
      ],
      "metadata": {
        "id": "Ovsi7b6AKy4h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ipc = IPC_Self_learning_Model(offence_)"
      ],
      "metadata": {
        "id": "f_EzKlEALOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f03f78-b684-4120-babb-b02cc1c69db0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 432ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ipc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55jsd4TULQaV",
        "outputId": "b1a74451-8db2-4d1a-d777-5289b8e49161"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['146 IPC', '302 IPC', '148 IPC', '147 IPC']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}